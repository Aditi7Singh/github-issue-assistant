# GitHub API (no token needed for public repos, but recommended for higher rate limits)
# GITHUB_TOKEN=your_github_token_here

# Caching (seconds) to reduce GitHub API calls
GITHUB_CACHE_TTL=300

# LLM Provider selection: openai | gemini
LLM_PROVIDER=openai

# OpenAI settings (required if LLM_PROVIDER=openai)
# Get a key: https://platform.openai.com/
OPENAI_API_KEY=your_openai_api_key_here
# Optional custom model
OPENAI_MODEL=gpt-4o-mini

# Google Gemini settings (required if LLM_PROVIDER=gemini)
# Get a key: https://ai.google.dev/
# GEMINI_API_KEY=your_gemini_api_key_here
# GEMINI_MODEL=gemini-1.5-flash

# Frontend configuration
# If deploying frontend separately, set the backend API base URL here
# API_BASE_URL=http://localhost:8000
